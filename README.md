# Bot de Scraping Web & Automatisation

Ce projet est un bot Python qui automatise la r√©cup√©ration de donn√©es sur le web, leur stockage dans un fichier Excel, et leur envoi par email. Il utilise des outils comme **BeautifulSoup**, **Selenium**, **OpenPyXL**, et **smtplib** pour scraper des sites statiques et dynamiques, g√©n√©rer des rapports, et partager les r√©sultats automatiquement.

---

## üéØ Fonctionnalit√©s actuelles

Le bot ex√©cute ces t√¢ches en une seule commande (`python main.py`) :

1. **Scraping statique avec BeautifulSoup** :
   - **Quoi** : R√©cup√®re les **titres** et **prix** des livres sur [books.toscrape.com](https://books.toscrape.com/).
   - **Comment** : Utilise `requests` pour t√©l√©charger la page HTML, puis `BeautifulSoup` pour extraire les donn√©es via des s√©lecteurs HTML (ex. `<article class="product_pod">`).
   - **Exemple** : "A Light in the Attic, ¬£51.77".
   - **Fichier** : `scripts/scraper.py`.

2. **Sauvegarde dans Excel avec OpenPyXL** :
   - **Quoi** : Cr√©e un fichier `data/livres.xlsx` avec deux colonnes : "Titre" et "Prix".
   - **Comment** : `openpyxl` g√©n√®re un classeur, ajoute une ligne d‚Äôen-t√™te, puis ins√®re chaque livre extrait.
   - **R√©sultat** : Un tableau clair dans `data/`.
   - **Fichier** : `main.py`.

3. **Scraping dynamique avec Selenium** :
   - **Quoi** : Recherche "python book" sur Amazon.fr et extrait le prix du premier r√©sultat (ex. "41‚Ç¨").
   - **Comment** : Ouvre Chrome en mode silencieux (headless) via `selenium`, simule une recherche dans la barre de recherche (ID `twotabsearchtextbox`), et r√©cup√®re le prix (classe `a-price-whole`).
   - **Fichier** : `scripts/automation.py`.

4. **Envoi d‚Äôemail avec smtplib** :
   - **Quoi** : Envoie `livres.xlsx` par email avec un message incluant le prix Amazon.
   - **Comment** : Utilise `smtplib` pour se connecter √† Gmail (via SMTP), et `email.mime` pour joindre le fichier et formater le message.
   - **Fichier** : `scripts/email_sender.py`.

### Exemple de logs apr√®s ex√©cution :
```
D√©but du scraping...
Fichier Excel sauvegard√© : data/livres.xlsx
Prix d‚Äôun livre Python sur Amazon : 41‚Ç¨
Email envoy√© avec succ√®s !
```

---

## üõ†Ô∏è Structure du projet
```
üìÇ scraping_bot
‚îú‚îÄ‚îÄ üìÇ venv               # Environnement virtuel
‚îú‚îÄ‚îÄ üìÇ data               # Fichiers Excel g√©n√©r√©s (ex. livres.xlsx)
‚îú‚îÄ‚îÄ üìÇ drivers            # ChromeDriver pour Selenium
‚îú‚îÄ‚îÄ üìÇ scripts            # Modules sp√©cifiques
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ scraper.py     # Scraping statique avec BeautifulSoup
‚îÇ   ‚îú‚îÄ‚îÄ üìÑ automation.py  # Automatisation dynamique avec Selenium
‚îÇ   ‚îî‚îÄ‚îÄ üìÑ email_sender.py # Envoi d‚Äôemails avec smtplib
‚îú‚îÄ‚îÄ üìÑ main.py            # Script principal qui orchestre tout
‚îú‚îÄ‚îÄ üìÑ config.py          # Configuration (URLs, emails, chemins)
‚îú‚îÄ‚îÄ üìÑ requirements.txt   # D√©pendances
‚îú‚îÄ‚îÄ üìÑ README.md          # Ce fichier
```

---

## üìã Pr√©requis

- **Python 3.12** : [python.org/downloads](https://www.python.org/downloads/), coche "Add Python to PATH" lors de l‚Äôinstallation.
- **Google Chrome** : Install√© sur ton PC (v√©rifie la version via Menu > Aide > √Ä propos).
- **ChromeDriver** :
  - Compatible avec ta version de Chrome (ex. 134.x).
  - T√©l√©charge depuis [googlechromelabs.github.io/chrome-for-testing/](https://googlechromelabs.github.io/chrome-for-testing/) :
    1. Va dans "Stable" ou "Known Good Versions".
    2. Trouve la version correspondant √† Chrome (ex. 134.x).
    3. T√©l√©charge `chromedriver-win32.zip`, extrais `chromedriver.exe`, et place-le dans `drivers/`.
- **Compte Gmail** : Cr√©e un mot de passe d‚Äôapplication via "G√©rer votre compte Google" > "S√©curit√©" > "Mot de passe d‚Äôapplication".

---

## üöÄ Installation

1. **Cr√©e la structure** :
   ```powershell
   cd C:\Users\ASUS\Desktop\
   mkdir scraping_bot
   cd scraping_bot
   mkdir venv data drivers scripts
   ```

2. **Cr√©e et active l‚Äôenvironnement virtuel** :
   ```powershell
   python -m venv venv
   .\venv\Scripts\activate
   ```

3. **Installe les d√©pendances** :
   - √âdite `requirements.txt` :
     ```
     requests==2.32.3
     beautifulsoup4==4.12.3
     selenium==4.25.0
     openpyxl==3.1.5
     ```
   - Puis :
     ```powershell
     pip install -r requirements.txt
     ```

4. **Configure `config.py`** :
   - Mets √† jour :
     - `EMAIL_SENDER` : Ton adresse Gmail.
     - `EMAIL_PASSWORD` : Ton mot de passe d‚Äôapplication.
     - `EMAIL_RECEIVER` : L‚Äôadresse de destination.
     - `CHROMEDRIVER_PATH` : `"drivers/chromedriver.exe"`.

5. **Ajoute ChromeDriver** :
   - Place `chromedriver.exe` dans `drivers/` (voir Pr√©requis).

---

## ‚ñ∂Ô∏è Utilisation

- Lance le bot :
  ```powershell
  python main.py
  ```
- R√©sultats :
  - `data/livres.xlsx` contient les donn√©es scrap√©es.
  - Un email arrive avec le fichier et le prix Amazon.

---

## üåü Options d‚Äôam√©lioration

1. **Scraper plus de pages** :
   - **Ajout** : Boucle dans `scraper.py` pour scraper plusieurs pages :
     ```python
     def scrape_books(url, max_pages=3):
         book_data = []
         for page in range(1, max_pages + 1):
             page_url = f"{url}catalogue/page-{page}.html"  # Pages pagin√©es
             response = requests.get(page_url)
             soup = BeautifulSoup(response.text, "html.parser")
             books = soup.find_all("article", class_="product_pod")
             for book in books:
                 title = book.h3.a["title"]
                 price = book.find("p", class_="price_color").text
                 book_data.append([title, price])
         return book_data
     ```
   - **Effet** : Plus de livres dans `livres.xlsx`.

2. **Planification automatique** :
   - **Ajout** : Utilise `schedule` (`pip install schedule`) :
     ```python
     import schedule
     import time
     def job():
         main()
     schedule.every().day.at("08:00").do(job)
     while True:
         schedule.run_pending()
         time.sleep(60)
     ```
   - **Effet** : Ex√©cution quotidienne automatique.

3. **Surveiller les prix** :
   - **Ajout** : Boucle dans `automation.py` pour plusieurs produits :
     ```python
     def monitor_prices(products, driver_path):
         prices = {}
         driver = webdriver.Chrome(service=Service(driver_path), options=Options())
         for product in products:
             driver.get("https://www.amazon.fr")
             search_box = driver.find_element(By.ID, "twotabsearchtextbox")
             search_box.send_keys(product)
             search_box.submit()
             driver.implicitly_wait(2)
             price = driver.find_element(By.CLASS_NAME, "a-price-whole").text
             prices[product] = price
         driver.quit()
         return prices
     ```
   - **Effet** : Suivi multi-produits.

4. **Interface graphique** :
   - **Ajout** : Utilise `tkinter` pour une fen√™tre de saisie.
   - **Effet** : Contr√¥le convivial sans terminal.

5. **Plus de sites** :
   - **Ajout** : Nouvelles fonctions dans `scraper.py` ou `automation.py` avec des s√©lecteurs adapt√©s.
   - **Effet** : Scraping multi-sources.

---

## üöÄ Potentiel avec modifications

- **Tracker de prix** : Alerte si un prix baisse sous un seuil.
- **Agr√©gateur** : Compile donn√©es de multiples sites (ex. avis, stats).
- **Assistant e-commerce** : Remplit des formulaires d‚Äôachat.
- **Rapports avanc√©s** : Ajoute des graphiques avec `matplotlib`.

---

## üõ†Ô∏è D√©pannage

- **ChromeDriver incompatible** :
  - V√©rifie ta version Chrome (Menu > Aide > √Ä propos) et t√©l√©charge le ChromeDriver correspondant.
- **Email ne part pas** :
  - V√©rifie `EMAIL_PASSWORD` (doit √™tre un mot de passe d‚Äôapplication).
- **Amazon bloque Selenium** :
  - D√©sactive `--headless` dans `automation.py` :
    ```python
    chrome_options = Options()  # Sans add_argument("--headless")
    ```

---

## üéâ Conclusion

Ce bot est une introduction solide √† l‚Äôautomatisation et au scraping web. Il montre comment combiner des outils Python pour des t√¢ches pratiques. Avec les am√©liorations propos√©es, il peut devenir un assistant personnalis√© ou un outil professionnel. Explore, modifie, et fais-en ce que tu veux !
